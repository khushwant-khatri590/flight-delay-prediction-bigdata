{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3316c0",
   "metadata": {},
   "source": [
    "\n",
    "# ✈️ Flight Delay Prediction Using PySpark and Google Cloud\n",
    "\n",
    "This notebook demonstrates an end-to-end big data pipeline for predicting flight delays using PySpark on Google Cloud Platform (GCP). The dataset used contains millions of airline records from the Bureau of Transportation Statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f974325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"FlightDelayPrediction\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace with your GCS path\n",
    "data = spark.read.csv(\"gs://your-bucket/airline_data.csv\", header=True, inferSchema=True)\n",
    "data.printSchema()\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cca354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create binary target variable\n",
    "data = data.withColumn(\"IsDelayed\", when(col(\"ArrDelay\") > 15, 1).otherwise(0))\n",
    "\n",
    "# Select relevant columns\n",
    "columns = [\"Carrier\", \"DepTime\", \"Distance\", \"DayOfWeek\"]\n",
    "data = data.select(columns + [\"IsDelayed\"]).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert DepTime to hour\n",
    "data = data.withColumn(\"DepHour\", (col(\"DepTime\") / 100).cast(\"int\")).drop(\"DepTime\")\n",
    "\n",
    "# StringIndexer for categorical features\n",
    "carrier_indexer = StringIndexer(inputCol=\"Carrier\", outputCol=\"CarrierIndexed\")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"CarrierIndexed\", \"DepHour\", \"Distance\", \"DayOfWeek\"],\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression Model\n",
    "lr = LogisticRegression(labelCol=\"IsDelayed\", featuresCol=\"features\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[carrier_indexer, assembler, scaler, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94101c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"IsDelayed\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test ROC-AUC: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b83d16",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Conclusion\n",
    "\n",
    "- Successfully built a distributed logistic regression pipeline using PySpark and GCP\n",
    "- Achieved solid ROC-AUC score using basic airline features\n",
    "- Project demonstrates practical use of cloud-scale data engineering and ML\n",
    "\n",
    "Further improvements could include trying other models (Random Forest, GBT) or tuning hyperparameters.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
